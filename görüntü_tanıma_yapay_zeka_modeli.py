# -*- coding: utf-8 -*-
"""Görüntü Tanıma Yapay Zeka Modeli

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_gXKBO12DzXOo1xu6Bb1oQn-gsgmeR0-
"""

# İlk olarak, gerekli kütüphaneleri yükleyelim.
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np
import os
import zipfile
import urllib.request

# Google Colab'da çalıştığımızı doğrulamak için Google Drive'ı bağlayabilirsiniz.
from google.colab import drive
drive.mount('/content/drive')


# Dataset'i indirelim ve zip dosyasını açalım.
url = "http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz"
urllib.request.urlretrieve(url, '102flowers.tgz')

# Dosyayı çıkaralım
!tar -xvzf 102flowers.tgz

# Etiket dosyasını da indirelim
url = "http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat"
urllib.request.urlretrieve(url, 'imagelabels.mat')

import scipy.io

# Etiketleri yükleyelim
labels = scipy.io.loadmat('imagelabels.mat')['labels'][0]

# Dataset klasör yapısını oluşturup resimleri ve etiketleri yerleştirelim
import shutil

dataset_path = 'flowers_dataset'
os.makedirs(dataset_path, exist_ok=True)

for i in range(1, 103):
    os.makedirs(os.path.join(dataset_path, str(i)), exist_ok=True)

for i, label in enumerate(labels):
    src = f'jpg/image_{i+1:05d}.jpg'
    dst = os.path.join(dataset_path, str(label), f'image_{i+1:05d}.jpg')
    shutil.move(src, dst)


# ImageDataGenerator kullanarak veri artırma yapalım
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2  # verinin %20'si validasyon için ayrılacak
)

train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)


# VGG16 modelini yükleyelim (pre-trained)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Yeni bir model oluşturalım
model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(102, activation='softmax')
])

# Modeli derleyelim
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Modeli eğitelim
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=validation_generator
)


# Eğitim ve validasyon kayıplarını ve doğruluklarını görselleştirelim
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(20)

plt.figure(figsize=(12, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()